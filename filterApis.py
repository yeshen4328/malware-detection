import pickle
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
import matplotlib.pyplot as plt
import os
from multiprocessing import Process
from BuildingModel import APK
def filterRawApis():
    dic = []
    fout = open("new_apis1.txt",'w')
    with open("apis_from_datasets.txt",'r') as lines:
        for line in lines:
            if(not "<init>" in line and not "<clinit>" in line and not"$" in line):
                if(line.startswith("android")):
                    if(line[7] == '.'):
                        split_space = line.split(" ")[0].replace(":","").split(".")
                        classes = split_space[-1]
                        if(len(classes)>=3):
                            fout.write(line)
    fout.close()

def countClasses():
    dict = {}
    with open("new_apis_filtered.txt",'r') as lines:
        for line in lines:
            split = line.split(' ')[0].replace(':','')
            if(dict.has_key(split)):
                dict[split] = dict[split] + 1
            else:
                dict[split] = 1
    fout = open("classes.txt",'w')
    for k,v in dict.iteritems():
        fout.write(k + ' ' + str(v) + '\n')
    fout.close()

def cluster():
    classes = {}
    clas_encoding = {}
    with open("new_apis_filtered.txt", 'r') as lines:
        for method in lines:
            method = method.split('->')[0]
            method_class = method.split(' ')[0]
            if(not method_class in classes):
                classes[method_class] = [method]
            else:
                classes[method_class].append(method)
    fout = open('apiClustered.txt','w')
    max = 0
    i = 1
    methods_codes_dict = {}
    for v in classes.values():
        if(len(v) > max):
            max = len(v)
        for method  in v :
            code = encoding(i)
            fout.write(method + '->' + code +"\n")
            methods_codes_dict[method] = code
            i = i + 1
    print(max)
    pickle.dump(methods_codes_dict, open('methods_codes_dict.pkl','wb'))
def encoding(index):
    out = [0 for x in range(13)]
    _bin = bin(index)
    str_bin = str(_bin)
    str_bin2 = str_bin[2:]
    i = 13 - len(str_bin2)
    for stri in str_bin2:
        out[i] = stri
        i = i + 1
    str_out = str(out).replace('\'','').replace('[','').replace(']','')
    return str_out


class ducument(object):
    def __init__(self, file):
        self.file = file
    def __iter__(self):
        with open(self.file) as lines:
            for id, line in enumerate(lines):
                line = line.replace('\n','')
                yield TaggedDocument(line, [id])


def api2vec():
    #remove parameter from the api call--->>

    fo = open('apis_for_api2vec.txt','w')
    with open('apis_from_datasets.txt','r') as lines:
        for line in lines:
            try:
                if('selfdefined'in line):
                    sentence = ['selfdefined']
                    print('ok')
                else:
                    line = line.split('->')[0]
                    classes = line.split(': ')[0]
                    method = line.split(': ')[1]
                    classes = classes.split('.')
                    #return_type = method.split(' ')[0].split('.')
                    method_name = method.split(' ')[1].split('(')[0]
                    sentence = classes + [method_name]
                for words in sentence:
                    fo.write(words + ' ')
                fo.write('\n')
            except IndexError:
                print(line)
    fo.close()

    documents = ducument('apis_for_api2vec.txt')
    model = Doc2Vec(documents, size=20, window=8, min_count=5, workers=4)
    model.save('apimodel')
def test():
    model = Doc2Vec.load('apimodel')
    with open('apiClustered.txt','r') as lines:
        for i, line in enumerate(lines):
            if(i > 71):
                break

            if('android.app.Service' in line):
                line = line.split('->')[0]
                classes = line.split(': ')[0]
                method = line.split(': ')[1]
                classes = classes.split('.')
                #return_type = method.split(' ')[0].split('.')
                method_name = method.split(' ')[1].split('(')[0]
                sentence = classes + [method_name]
                vec = model.infer_vector(sentence)
                plt.bar(range(100), height=vec)
                plt.show()

def filterGraph():
    path = "../test_raw_graph"
    target_dir = "../test_graph_filtered/"
    datasets = os.listdir(path)
    for dataset in datasets:
        set_dir_path = path + '/' + dataset
        apks = os.listdir(set_dir_path)

        core = 11
        sampleNum = len(apks)
        samplesPerCore = sampleNum // core
        processlist = []
        apksPerCore = []
        for i in range(core):
            if (sampleNum - samplesPerCore * i >= samplesPerCore):
                apksPerCore = apks[i * samplesPerCore: (i + 1) * samplesPerCore]
            else:
                apksPerCore = apks[i * samplesPerCore: sampleNum]
            processlist.append(Process(target=taskPerCore, args=(apksPerCore, set_dir_path, target_dir,dataset)))
            processlist[i].daemon = True
            processlist[i].start()
        for i in range(core):
            processlist[i].join()

def MultiCoreProcess(path, target_dir, taskPerCore):
    datasets = os.listdir(path)
    for dataset in datasets:
        set_dir_path = path + '/' + dataset
        apks = os.listdir(set_dir_path)
        core = 11
        sampleNum = len(apks)
        samplesPerCore = sampleNum // core
        processlist = []
        apksPerCore = []
        for i in range(core):
            if (sampleNum - samplesPerCore * i >= samplesPerCore):
                apksPerCore = apks[i * samplesPerCore: (i + 1) * samplesPerCore]
            else:
                apksPerCore = apks[i * samplesPerCore: sampleNum]
            processlist.append(Process(target=taskPerCore, args=(apksPerCore, set_dir_path, target_dir,dataset)))
            processlist[i].daemon = True
            processlist[i].start()
        for i in range(core):
            processlist[i].join()
overwrite = False
def taskPerCore(apks, dir, target_dir,dataset):
    for apk in apks:
        if(not overwrite and os.path.isfile(target_dir + dataset +'/'+ apk)):
            print('jump '+apk)
            continue
        print('process '+apk)
        fo = open(target_dir + dataset +'/'+ apk,'w')
        try:
            with open(dir + '/' + apk, 'r') as  lines:

                for line in lines:
                    callees_no_dulp = []
                    call = []
                    parts = line.split('==>')
                    caller = parts[0].strip()
                    callees = parts[1]
                    callees = callees.replace('\\n', '').split(', ')
                    # process caller
                    for callee in callees:
                        callee = callee.replace('[\'<', '').replace('>\']\n', '').replace('\'<', '').replace('>\'','').strip()
                        if(not '<'+callee+'>' in callees_no_dulp):
                            callees_no_dulp.append('<'+callee+'>')
                    fo.write(caller +'==>'+ str(callees_no_dulp) + '\n')
                    callees_no_dulp = None
            fo.close()
        except UnicodeDecodeError:
            print('UnicodeDecodeError')
            pass
def count_longest():
    root = '../apk_graph_labeld/'
    apks = os.listdir(root)
    maxl = 0
    for apk in apks:
        path = root + apk
        g = pickle.load(open(path,'rb'))
        maxl = max(maxl, len(g.graph))
        print(maxl)
        g= None
    print(maxl)
def removeEmpty():
    path = '../apk_graph_vec_test/'
    list = os.listdir(path)
    for p in list:
        struct = pickle.load(open(path + p,'rb'))
        graph = struct.graph
        if(len(graph) == 0):
            os.remove(path + p)
        struct = None
import csv
def  rangeapi():
    csvFile = open('api_permission_mapping_5.1.1.csv','r')
    sensitiveapi = []
    reader = csv.reader(csvFile)
    for i,item in enumerate(reader):
        if(i == 0):
            continue
        fullapi = item[0] + ':' + item[1]
        if(not fullapi in sensitiveapi):
            sensitiveapi.append(fullapi)
    sensitiveapi.sort(reverse=False)
    txt = open('sensitive_api_5.1_sorted.txt','w')
    for i in sensitiveapi:
        txt.write(i)
        txt.write('\n')
if __name__ == "__main__":
    #filterRawApis()
    #countClasses()
    #cluster()
    #api2vec()
    #filterGraph()
    #count_longest()
    rangeapi()
    #removeEmpty()

