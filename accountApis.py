import os
from multiprocessing import Pool, Process, Queue
import pickle
from BuildingModel import APK

def isFramwrokApis(api , packages):
    for line in packages:
        if api.startswith(line):
            return True

    return False

def combine(dic1, dic2):
    for k,v in dic2.items():
        if(k in dic1):
            dic1[k] = dic1[k] + dic2[k]
        else:
            dic1[k] = dic2[k]

def travesRoot(apiDic, root, packages, index):
    #root = "H:\\sourceTree\\graphs\\benign"
    apks = os.listdir(root)
    #apiDic = {}
    for apk in apks:
        apk_path = root + "\\" + apk
        with open(apk_path) as lines:
            for line in lines:
                parts = line.split('==>')
                caller = parts[0]
                callees = parts[1]
                # process caller
                # caller = caller.replace('<', '').replace('>', '').strip()
                # if (apiDic.has_key(caller)):
                #     apiDic[caller] = apiDic[caller] + 1
                # else:
                #     apiDic[caller] = 1
                # process callee
                callees = callees.replace('\\n','').split(', ')

                for callee in callees:
                    callee = callee.replace('[\'<', '').replace('>\']\n', '').replace('\'<','').replace('>\'','').strip()
                    print(callee)
                    if (isFramwrokApis(callee, packages)):
                        if (apiDic.has_key(callee)):
                            apiDic[callee] = apiDic[callee] + 1
                        else:
                            apiDic[callee] = 1
                    else:
                        apiDic['selfdefined'] = 1
    fout = open(str(index) + ".txt",'wb')
    pickle.dump(apiDic, fout)
    fout.close()
    return apiDic

def main():
    packages = []
    with open("PackagesOcc.txt",'r') as lines:
        for line in lines:
            packages.append(line.replace('\n',''))
    path = "../sourceTree/graphs"

    datasets = os.listdir(path)
    setNum = len(datasets)
    apiDic = []
    fout = open("apis_from_datasets.txt",'w')
    processlist = []
    apiDicList = []
    # for db in datasets:
    #     travesRoot(apiDic, path + "/" + db, packages)
    # for k,v in apiDic.iteritems():
    #  fout.write(k + "->" + str(v) + "\n")
    queue = Queue()
    for i in range(len(datasets)):
        apiDicList.append({})
    for i in range(len(datasets)):
        processlist.append(Process(target=travesRoot, args=(apiDicList[i], path + "/" + datasets[i], packages, i)))
        processlist[i].daemon = True
        processlist[i].start()
    for i in range(len(processlist)):
        processlist[i].join()
    dic = {}
    for i in range(len(datasets)):
        if(i == 0):
            fin = open(str(i)+".txt",'rb')
            dic = pickle.load(fin)
        fin = open(str(i) + ".txt", 'rb')
        combine(dic, pickle.load(fin))
    for k,v in dic.iteritems():
        fout.write(k + "->" + str(v) + "\n")
    fout.close()

def account(apks, root, index):
    api_dict = {}
    for apk in apks:
        apk_path = root + "\\" + apk
        with open(apk_path) as lines:
            print(apk)
            for line in lines:
                parts = line.split('==>')
                caller = parts[0]
                callees = parts[1]
                callees = callees.replace('\\n', '').split(', ')
                if(caller == '<dummyMainClass: void dummyMainMethod(java.lang.String[])>'):
                    for callee in callees:
                        callee = callee.replace('[\'<', '').replace('>\']\n', '').replace('\'<', '').replace('>\'','').strip()
                        callee_m = callee.split(': ')[1]
                        if(not callee_m in api_dict):
                            api_dict[callee_m] = 1
                        else:
                            api_dict[callee_m] = api_dict[callee_m] + 1
                break
    fout = open(str(index) + ".txt", 'wb')
    pickle.dump(api_dict, fout)
    fout.close()
def accountMethodsInDummy():
    path = "../filterGraph"
    datasets = os.listdir(path)
    fout = open("apis_in_dummyMain.txt", 'w')
    processlist = []
    # for i in range(len(datasets)):
    #     processlist.append(Process(target=account, args=(os.listdir(path+'/'+datasets[i]), path+'/'+datasets[i], i)))
    #     processlist[i].daemon = True
    #     processlist[i].start()
    # for i in range(len(processlist)):
    #     processlist[i].join()
    dic = {}
    for i in range(len(datasets)):
        fin = open(str(i) + ".txt", 'rb')
        tmp  = pickle.load(fin)

        fo = open('apis_in_'+datasets[i] + '.txt','w')
        apilist = []
        for k, v in tmp.items():
            apilist.append((k, v))
        apilist.sort(key=lambda x: x[1], reverse=True)
        for (k, v) in apilist:
            if (not '<init>' in k and not '<clinit>' in k):
                fo.write(k + "->" + str(v) + "\n")
        fo.close()


        combine(dic, tmp)
    apilist=[]
    top50 = []
    for k,  v in dic.items():
        apilist.append((k,v))
    apilist.sort(key=lambda x:x[1], reverse= True)
    i = 0
    for (k, v) in apilist:
        if(not '<init>' in k and not '<clinit>' in k):
            if(i < 50):
                top50.append(k)
                i += 1
            fout.write(k + "->" + str(v) + "\n")
    fout.close()
    pickle.dump(top50, open('./entrypoint.pkl','wb'))
    pickle.dump(dic, open('./apis_in_dummyMain.pkl','wb'))

if __name__ == "__main__":
    #main()
    #accountMethodsInDummy()
    a=pickle.load(open('123.pkl','rb'))
    len(a.graph)
